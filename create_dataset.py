# -*- coding: utf-8 -*-
"""create_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AoGO_xWXy5_31v8Au1kzRwLLyU9QVOOz
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Load the data
#   - Load the metro_all.csv dataset into a pandas DataFrame
#   - Select the relevant columns: 'datetime', 'Load', 'TOA_SW_DWN', 'Load_previous_hour'
#   - Convert the 'datetime' column to a datetime object and set it as the index
data = pd.read_csv("metro_all.csv")
columns_to_keep = ['datetime', 'Load', 'TOA_SW_DWN', 'Load_previous_hour']
df = data[columns_to_keep]
df['datetime'] = pd.to_datetime(df['datetime'])
df.set_index('datetime', inplace=True)

# Normalize the data
#   - Normalize the 'Load', 'TOA_SW_DWN', and 'Load_previous_hour' columns using MinMaxScaler
load_scaler = MinMaxScaler()
temp_scaler = MinMaxScaler()

df['Load'] = load_scaler.fit_transform(df[['Load']])
df['TOA_SW_DWN'] = temp_scaler.fit_transform(df[['TOA_SW_DWN']])
df['Load_previous_hour'] = temp_scaler.fit_transform(df[['Load_previous_hour']])

# Split the data into train, validation, and test sets
#   - Calculate the total size of the dataset
#   - Split the dataset into 70% training, 20% validation, and 10% testing
total_size = len(df)
train_size = int(total_size * 0.7)
valid_size = int(total_size * 0.2)
test_size = total_size - train_size - valid_size

train = df.iloc[:train_size]
valid = df.iloc[train_size:train_size+valid_size]
test = df.iloc[train_size+valid_size:]

# Create datasets for time series prediction
#   - Create a function to create training, validation, and test datasets
#   - Set the number of time steps to 24
def create_dataset(X, y, time_steps):
    Xs = []
    ys = []
    for i in range(len(X) - time_steps):
        v = X.iloc[i:(i + time_steps)]
        Xs.append(v.values)
        if isinstance(y, pd.DataFrame):
            ys.append(y.iloc[i + time_steps].values)
        else:
            ys.append(y.iloc[i + time_steps])
    return np.array(Xs), np.array(ys)

time_steps = 24

X_train, y_train = create_dataset(train[['Load', 'TOA_SW_DWN', 'Load_previous_hour']], train['Load'], time_steps)
X_valid, y_valid = create_dataset(valid[['Load', 'TOA_SW_DWN', 'Load_previous_hour']], valid['Load'], time_steps)
X_test, y_test = create_dataset(test[['Load', 'TOA_SW_DWN', 'Load_previous_hour']], test['Load'], time_steps)

print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape)